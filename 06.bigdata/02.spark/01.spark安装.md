[TOC]

#spark安装

##下载spark1.6.1
[下载地址](http://apache.opencas.org/spark/spark-1.6.1/spark-1.6.1-bin-hadoop2.6.tgz)
##上传spark
##安装java
参见[jdk安装](../../03.linux/01.centos/02.java相关配置/01.jdk安装和环境变量配置.md)
##安装scala
[scala安装](../../03.linux/01.centos/06.常用工具配置/02.scala安装配置.md)
##安装hadoop
[hadoop分布式安装](../01.hadoop/04.hadoop分布式安装.md)  
[hadoop伪分布式安装](../01.hadoop/02.hadoop伪分布式安装.md)  

##配置环境变量
	
	vim ~/.bashrc
	SPARK_HOME=/home/hadoop/app/spark-1.6.1
	PATH=$PATH:/$SPARK_HOME/bin
	export PATH SPARK_HOME
source ~/.bashrc使配置生效  

##配置spark

[spark伪分布式](01.dir/spark配置文件/1.6.1/伪分布式安装)
[spark分布式](01.dir/spark配置文件/1.6.1/分布式安装)

##修改spark-env.sh

	cp $SPARK_HOME/conf/spark-env.sh.template $SPARK_HOME/conf/spark-env.sh

伪分布什么都不需要修改

##修改slaves
	
	vim $SPARK_HOME/conf/slaves

	hadoopallinone(根据需要配置)

##启动
启动hdfs  
启动spark  

	$SPARK_HOME/sbin/start-all.sh

##验证
启动浏览器
	
	http://hadoopallinone:8080  #浏览器地址
	$SPARK_HOME/bin/spark-shell  #启动spark-shell