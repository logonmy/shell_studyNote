[TOC]

#hbase分布式安装

##上传hbase安装包

##解压

	tar -zxvf hbase-1.1.3-bin.tar.gz

## 配置环境变量
	
	vim ~/.bashrc
	HBASE_HOME=/home/hadoop/app/hbase-1.1.3
	PATH=$PATH:$HBASE_HOME/bin
	export PATH HBASE_HOME

## 配置hbase集群，要修改3个文件（首先zk集群已经安装好了）

1.把hadoop的hdfs-site.xml和core-site.xml 放到${HBASE_HOME}/conf下

	cp ${HADOOP_HOME}/con/{hdfs-site.xml,core-site.xml} ${HBASE_HOME}/conf

2.修改${HBASE_HOME}/conf/hbase-env.sh  
	export JAVA_HOME=${JAVA_HOME}
	//告诉hbase使用外部的zk
	export HBASE_MANAGES_ZK=false
	
3 vim hbase-site.xml
	<configuration>
		<!-- 指定hbase在HDFS上存储的路径 -->
        <property>
                <name>hbase.rootdir</name>
                <value>hdfs://ns1/hbase</value>
        </property>
		<!-- 指定hbase是分布式的 -->
        <property>
                <name>hbase.cluster.distributed</name>
                <value>true</value>
        </property>
		<!-- 指定zk的地址，多个用“,”分割 -->
        <property>
                <name>hbase.zookeeper.quorum</name>
                <value>hadoop5:2181,hadoop6:2181,hadoop7:2181</value>
        </property>
	</configuration>
	
4 vim regionservers
	hadoop3
	hadoop4
	hadoop5
	hadoop6
	hadoop7
	3.2拷贝hbase到其他节点
		scp -r /weekend/hbase-0.96.2-hadoop2/ hadoop2:/weekend/
		scp -r /weekend/hbase-0.96.2-hadoop2/ hadoop3:/weekend/
		scp -r /weekend/hbase-0.96.2-hadoop2/ hadoop4:/weekend/
		scp -r /weekend/hbase-0.96.2-hadoop2/ hadoop5:/weekend/
		scp -r /weekend/hbase-0.96.2-hadoop2/ hadoop6:/weekend/
4.将配置好的HBase拷贝到每一个节点并同步时间。

5.启动所有的hbase

##启动zookeeper集群
[zookeeper环境搭建](../01.hadoop/05.zookeeper配置.md)
${ZOOKEEPER_HOME}/bin/
	分别启动zk
		./zkServer.sh start
	启动hdfs集群
		start-dfs.sh
	启动hbase，在主节点上运行：
		start-hbase.sh
6.通过浏览器访问hbase管理页面
	192.168.1.201:60010
7.为保证集群的可靠性，要启动多个HMaster
	hbase-daemon.sh start master